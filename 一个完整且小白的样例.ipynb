{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一个样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有看TensorFlow的源码的话，可能经常会看见这三行，原因嘛，这是TensorFlow家自定的<a href=\"https://www.tensorflow.org/community/style_guide?hl=zh-cn\">文档规范</a> \n",
    "<br>有人可能对 _future_ 有疑问, 从是啥，为啥两个方面来回答好了\n",
    "<br>1）是啥\n",
    "<br>答：<a href = \"https://docs.python.org/3/library/__future__.html\">是一个叫_future_的module呀</a>\n",
    "<br>2) 为啥\n",
    "<br>答：解决版本间的不兼容问题，例如我比较懒，下载python之后就懒得更新，当别人都已经用3.99时，我还在用3.00，3.99版本的print也许在输出时会自带十行回车，那么懒惰的我，从_future_这个module中导入print_function,就可以用3.99版本自带十行回车的炫酷输出了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import iris_data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管数据都在<a href> iris_data</a>中预处理了，我们还是需要看一眼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>120</th>\n",
       "      <th>4</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   120    4  setosa  versicolor  virginica\n",
       "0  6.4  2.8     5.6         2.2          2\n",
       "1  5.0  2.3     3.3         1.0          1\n",
       "2  4.9  2.5     4.5         1.7          2\n",
       "3  4.9  3.1     1.5         0.1          0\n",
       "4  5.7  3.8     1.7         0.3          0\n",
       "5  4.4  3.2     1.3         0.2          0\n",
       "6  5.4  3.4     1.5         0.4          0\n",
       "7  6.9  3.1     5.1         2.3          2\n",
       "8  6.7  3.1     4.4         1.4          1\n",
       "9  5.1  3.7     1.5         0.4          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "#s=requests.get(TRAIN_URL).content\n",
    "c=pd.read_csv(TRAIN_URL)\n",
    "c.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不知道为什么的，这个标题行似乎并不对--\n",
    "<br>按照<a>官方网站的解释</a>，这五列分别是：\n",
    "<br>萼片长；萼片宽；花瓣长；花瓣宽；种类（标签） //注：标签是0，1，2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恩，既然已经透漏了四个特征值，那么我们要做的任务就是：\n",
    "<br>通过萼片长，萼片宽，花瓣长和花瓣宽来判断鸢尾花的种类 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一点需要说明，该tutorial建立在<a>Estimator</a>基础上完成，关于Estimator的更多解释及代码，可以参考我翻译的另一个tutorial\n",
    "### 那么接下来，我们需要做以下工作：\n",
    "#### (1)创建输入函数\n",
    "#### (2)定义模型的特征列\n",
    "#### (3)初始化Estimator，指定特征列以及各种超参（如果不知道超参是什么的话，点击<a>这里</a>）\n",
    "#### (4)在Estimator上调用优化方法，传递适当的输入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_evaluation_set():\n",
    "    features = {'SepalLength': np.array([6.4, 5.0]),\n",
    "                'SepalWidth':  np.array([2.8, 2.3]),\n",
    "                'PetalLength': np.array([5.6, 3.3]),\n",
    "                'PetalWidth':  np.array([2.2, 1.0])}\n",
    "    labels = np.array([2, 1])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上只是从官网上copy下的样例，通常情况下，我们先要获取数据，在input_evaluation_set()将数据分离成合适的features部分，及label部分，在将这部分传入包含<a>tf.Dataset</a> API的train_input_fn()中，输出可以作为真正训练过程的输入\n",
    "<BR>这里为了方便起见就直接调用iris_data.load_data来获取训练及测试集啦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = iris_data.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来了，我们来定义特征列，在真实数据中，特征列的处理更为复杂，但这里只是举个🌰 \n",
    "<br> 以及，这里用到tf.feature_column来处理，具体请参照领一份tutorial<a> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可能想看一下特征列中都有啥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是第三步，定义一个Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/8l/j0ddzz_x75n85vq8tp86dwpr0000gn/T/tmptzmtf89p\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/8l/j0ddzz_x75n85vq8tp86dwpr0000gn/T/tmptzmtf89p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x120686c18>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[10, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果这是你第一次接触TensorFlow的话，恭喜你，你的第一个DNN已经定义好了 ~\n",
    "<br> 虽然我觉得非常明显，但还是解释一下好了，你刚刚定义了一个带有两层双隐层，每层有10个unit，输出层有三个unit(就是有三种类别)，特征列就是你刚刚看见的my_feature_columns 的小白版DNN分类器 -v-\n",
    "<BR>接下来，制定batch_size以及train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_steps = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来的工作是：\n",
    "#### 1）训练模型\n",
    "#### 2）评估训练模型准确率\n",
    "#### 3）使用已经训练的模型做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/8l/j0ddzz_x75n85vq8tp86dwpr0000gn/T/tmptzmtf89p/model.ckpt.\n",
      "INFO:tensorflow:loss = 161.19363, step = 1\n",
      "INFO:tensorflow:global_step/sec: 562.711\n",
      "INFO:tensorflow:loss = 11.6809025, step = 101 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.298\n",
      "INFO:tensorflow:loss = 9.929311, step = 201 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.128\n",
      "INFO:tensorflow:loss = 5.9321713, step = 301 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.302\n",
      "INFO:tensorflow:loss = 5.851366, step = 401 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.393\n",
      "INFO:tensorflow:loss = 2.5129728, step = 501 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.041\n",
      "INFO:tensorflow:loss = 5.1492662, step = 601 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.368\n",
      "INFO:tensorflow:loss = 4.1985073, step = 701 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.516\n",
      "INFO:tensorflow:loss = 3.329792, step = 801 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.139\n",
      "INFO:tensorflow:loss = 5.2057896, step = 901 (0.155 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/8l/j0ddzz_x75n85vq8tp86dwpr0000gn/T/tmptzmtf89p/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.12586.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1206867f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_x, train_y, batch_size),\n",
    "    steps=train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练完成后，我们用测试集来评估该模型的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-09-09:16:30\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/8l/j0ddzz_x75n85vq8tp86dwpr0000gn/T/tmptzmtf89p/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-09-09:16:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.054533932, global_step = 1000, loss = 1.6360179\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, batch_size = batch_size))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 93.3%的准确率！\n",
    "(其实一点也不高 你很有可能得到比我高的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，做个预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions from the model\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:iris_data.eval_input_fn(predict_x,\n",
    "                                            labels=None,\n",
    "                                            batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x12104d570>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict返回的是一个python的iterable(⊙v⊙)\n",
    "<br>你可能对这种数据类型有疑问\n",
    "<br>也可能没有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    #print(pred_dict)\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(iris_data.SPECIES[class_id],\n",
    "                          100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
