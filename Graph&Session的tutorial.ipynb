{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph & Sessions\n",
    "### 1.简介\n",
    "Tensorflow使用数据流图来表示你的计算模型，具体来说，就是每个单独操作之间的依赖关系。\n",
    "\n",
    "如果你打算直接使用低层API来构造你的模型的话，本篇tutorial对你会有很大帮助。高层API例如tf.estimator.Estimator及Keras对终端用户隐藏了Graph和Session的细节，但如果你想了解这些API是如何实现的话，这篇tutorial对你也许也有很大帮助。\n",
    "\n",
    "数据流是针对并行编程而言一种常用的编程模型，在一个数据流图中，节点表示计算单元，边表示数据的流量（被使用以及被创建），例如，在Tensorflow图中，tf.matmul操作(在图中表示为一个节点)将会使用两个矩阵(两个流入的边)以及产生一个输出的矩阵(流出的边)。\n",
    "\n",
    "或者，一个实际的神经网络例子：\n",
    "<img src=\"https://www.tensorflow.org/images/tensors_flowing.gif?hl=zh-cn\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.tf.Graph\n",
    "一个tf.Graph主要包含以下两类相关信息：\n",
    "* Graph的结构：就是刚刚说的节点和边啦\n",
    "* Graph集合：Tensorflow提供了存储Graph中元数据的通用机制。这个tf.add_to_collection方法使你可以通过键值来操作对象，以及tf.get_collection方法使你可以与某个键值相关的所有对象。大部分Tensorflow的library都使用以下特性：当你创建一个Variable时，该Variable将会自动被加入到名为“global variables”和“rainable variables”的集合中，当不久后你创建tf.train.Saver或者tf.train.Optimizer时，在这些集合中的Variable将被用为默认参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.构建Graph\n",
    "大多数Tensorflow程序都是从构建数据流图阶段开始，在这个阶段中，你唤起Tensorflow API函数构建新的操作节点以及Tensor对象(边)，并且将它们加入到tf.Graph实例中。Tensorflow提供一个默认图，隐式定义所有的API函数都在相同的上下文中，例如：\n",
    "* 调用tf.constant(42.0)创建单独的tf.Operation产生数值42.0，并且将它加入到默认图中，返回一个tensor表示当前常数的数值。\n",
    "\n",
    "大多数程序依赖各自的默认图，但一种情况是<a href =\"https://www.tensorflow.org/programmers_guide/graphs?hl=zh-cn#programming_with_multiple_graphs\"> Dealing with multiple graphs</a>。但是高层API，例如Estimator代替你来管理这些默认图，所以也会在训练以及评估的过程中自行创建不同的图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.操作命名\n",
    "一个Graph对象为它包含的操作定义了命名空间。Tensorflow为每个操作自动选择一个独一无二的名字，但自行命名会使你的程序更易读，也更容易debug。\n",
    "\n",
    "Tensorflow提供两种重命名operation的方式：\n",
    "* 使用name参数：tf.constant(42.0, name=\"answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'c_5:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "c_0 = tf.constant(0, name=\"c\")  # => operation named \"c\"\n",
    "\n",
    "# Already-used names will be \"uniquified\".\n",
    "c_1 = tf.constant(2, name=\"c\")  # => operation named \"c_1\"\n",
    "c_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf.name_scope方法允许你在特定的上下稳重给所有的操作创建前缀，如果某个scope的名字已经在当前上下文中使用，Tensorflow将自动在后面附上“_1”,\"_2\"这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"outer\"):\n",
    "    c_2 = tf.constant(2, name=\"c\")  # => operation named \"outer/c\"\n",
    "\n",
    "  # Name scopes nest like paths in a hierarchical file system.\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_3 = tf.constant(3, name=\"c\")  # => operation named \"outer/inner/c\"\n",
    "\n",
    "  # Exiting a name scope context will return to the previous prefix.\n",
    "    c_4 = tf.constant(4, name=\"c\")  # => operation named \"outer/c_1\"\n",
    "\n",
    "  # Already-used name scopes will be \"uniquified\".\n",
    "    with tf.name_scope(\"inner\"):\n",
    "        c_5 = tf.constant(5, name=\"c\")  # => operation named \"outer/inner_1/c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'outer/inner_1/c:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'outer/inner/c:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在TensorFlow可视化过程中，scope减少了可视化的复杂性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: 由tf.Operation隐式产生的tensor对象，自动用\"OP_NAME\":\"i\"的形式命名:\n",
    "* Op_Name:产生该tensor的操作的名称\n",
    "* i：在该操作产生一系列的输出中，该tensor的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.在不同的硬件中放置操作\n",
    "（略了，觉得买的起很多GPU的人不多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.类Tensor对象\n",
    "许多Tensorflow操作使用一个或者多个Tensor对象作为参数。例如，tf.matmul使用两个tensor对象，tf.add_n使用一列的tensor对象。为了方便起见，这些函数也接受类Tensor对象，并且隐式地转化为Tensor对象，类tensor对象包括以下几类：\n",
    "* tf.Tensor\n",
    "* tf.Variable\n",
    "* numpy.ndarray\n",
    "* list\n",
    "* Python中的bool, float, int, str\n",
    "同样，你也可以通过tf.register_tensor_conversion_function其他数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.在Session中执行Graph\n",
    "Tensorflow提供了tf.Session类来表示客户程序之间的链接，一个tf.Session对象提供进入本地机器或者运行分布式Tensorflow的远程设备。它同样保存Graph的信息以便于你可以有效运行多次相同运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1创建tf.Session\n",
    "如果你正在使用低层次的Tensorflow API，你可以按照以下方式创建Session："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a default in-process session.\n",
    "with tf.Session() as sess:\n",
    "      sess.run(c_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者创建一个远程session\n",
    "* with tf.Session(\"grpc://example.org:2222\"):\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为一个session拥有自己的物理资源(例如GPU和网络连接)，通常会使用上下文管理(在一个with模块中），当你退出某块时自动关闭session。在不使用with块的情况下创建一个session也是可能的，但是你需要显示的调用tf.Session.close来释放刚刚占用的所有资源。\n",
    "\n",
    "#### Note：Estimator将自动管理session，但这些API接受target或者config参数，含义如下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Session.init接受三个可选择的参数：\n",
    "* target：如果此处参数被留空的话，该session将只使用本地机器，然而，如果你指定grpc://URL到一个特定的Tensorflow服务器，那么该session具有该服务器上所有机器的进入权限。查看<a href=\"https://www.tensorflow.org/api_docs/python/tf/train/Server?hl=zh-cn\">tf.train.Server</a>如何创建Tensorflow服务器。\n",
    "* Graph：默认来说，一个新的session只可以运行当前Graph中包含的操作，如果你在你的程序中使用了多个图的话，你可以显示的定义一个tf.Graph来构建session\n",
    "* config：该参数允许你指定一个 tf.ConfigProto来控制session的行为，包括\n",
    "    * allow_soft_placement\n",
    "    * cluster_def\n",
    "    * graph_options.optimizer_options\n",
    "    * gpu_options.allow_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 使用 tf.Session.run 来执行操作\n",
    "tf.Session.run方法是执行tf.Operation或者估测tf.Tensor值的主要操作。你可以在tf.Session.run中传递一个或者多个tf.Operation或者tf.Tensor对象，Tensorflow会在需要计算结果的时候执行这些操作。\n",
    "\n",
    "tf.Session.run要求你指定一系列需要取回的值，也就是决定返回值，可能是一个tf.Operation，tf.Tensor或者是类tensor对象。这些要取回的对象决定了整个tf.Graph图的子图，也就是该子图包含所有在取回值列的操作或者tensor对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9986076e-01 1.3921809e-04]\n",
      " [6.3378370e-01 3.6621630e-01]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[37.0, -23.0], [1.0, 4.0]])\n",
    "w = tf.Variable(tf.random_uniform([2, 2]))\n",
    "y = tf.matmul(x, w)\n",
    "output = tf.nn.softmax(y)\n",
    "init_op = w.initializer\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Run the initializer on `w`.\n",
    "    sess.run(init_op)\n",
    "\n",
    "  # Evaluate `output`. `sess.run(output)` will return a NumPy array containing\n",
    "  # the result of the computation.\n",
    "    print(sess.run(output))\n",
    "\n",
    "  # Evaluate `y` and `output`. Note that `y` will only be computed once, and its\n",
    "  # result used both to return `y_val` and as an input to the `tf.nn.softmax()`\n",
    "  # op. Both `y_val` and `output_val` will be NumPy arrays.\n",
    "    y_val, output_val = sess.run([y, output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，tf.Session.run也可以用字典作为输入，映射tensor对象(尤其是针对placeholder类型)，到具体数值。\n",
    "\n",
    "例如：\n",
    "* sess.run(y, {x: [1.0, 2.0, 3.0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Session.run也接受其他可选择的参数，使你可以指定调用，以及一个可选择的run_metadata参数允许你收集执行时的元参数，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[node {\n",
      "  name: \"MatMul_1/a\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\024B\\000\\000\\270\\301\\000\\000\\200?\\000\\000\\200@\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_1/shape\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_INT32\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\002\\000\\000\\000\\002\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_1/RandomUniform\"\n",
      "  op: \"RandomUniform\"\n",
      "  input: \"random_uniform_1/shape\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"seed2\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_1/sub\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        tensor_content: \"\\000\\000\\200?\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_1/mul\"\n",
      "  op: \"Mul\"\n",
      "  input: \"random_uniform_1/RandomUniform\"\n",
      "  input: \"random_uniform_1/sub\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_1/min\"\n",
      "  op: \"Const\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "        }\n",
      "        float_val: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"random_uniform_1\"\n",
      "  op: \"Add\"\n",
      "  input: \"random_uniform_1/mul\"\n",
      "  input: \"random_uniform_1/min\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"MatMul_1\"\n",
      "  op: \"MatMul\"\n",
      "  input: \"MatMul_1/a\"\n",
      "  input: \"random_uniform_1\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_a\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"transpose_b\"\n",
      "    value {\n",
      "      b: false\n",
      "    }\n",
      "  }\n",
      "}\n",
      "node {\n",
      "  name: \"_retval_MatMul_1_0_0\"\n",
      "  op: \"_Retval\"\n",
      "  input: \"MatMul_1\"\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  attr {\n",
      "    key: \"T\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"index\"\n",
      "    value {\n",
      "      i: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "library {\n",
      "}\n",
      "versions {\n",
      "  producer: 24\n",
      "}\n",
      "]\n",
      "dev_stats {\n",
      "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
      "  node_stats {\n",
      "    node_name: \"_SOURCE\"\n",
      "    all_start_micros: 1521353938530726\n",
      "    op_start_rel_micros: 155\n",
      "    op_end_rel_micros: 155\n",
      "    all_end_rel_micros: 474\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_SOURCE = NoOp()\"\n",
      "    scheduled_micros: 1521353938530522\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_1/a\"\n",
      "    all_start_micros: 1521353938531349\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 270\n",
      "    all_end_rel_micros: 279\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 4793683456\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_1/a = Const()\"\n",
      "    scheduled_micros: 1521353938531200\n",
      "    memory_stats {\n",
      "      host_persistent_memory_size: 16\n",
      "      host_persistent_tensor_alloc_ids: -1\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_1/shape\"\n",
      "    all_start_micros: 1521353938531631\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 4\n",
      "    all_end_rel_micros: 7\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_INT32\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 8\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 4793685024\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_1/shape = Const()\"\n",
      "    scheduled_micros: 1521353938531628\n",
      "    memory_stats {\n",
      "      host_persistent_memory_size: 8\n",
      "      host_persistent_tensor_alloc_ids: -1\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_1/sub\"\n",
      "    all_start_micros: 1521353938531663\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 3\n",
      "    all_end_rel_micros: 7\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 4\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 4426801120\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_1/sub = Const()\"\n",
      "    scheduled_micros: 1521353938531638\n",
      "    memory_stats {\n",
      "      host_persistent_memory_size: 4\n",
      "      host_persistent_tensor_alloc_ids: -1\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_1/min\"\n",
      "    all_start_micros: 1521353938531673\n",
      "    op_end_rel_micros: 3\n",
      "    all_end_rel_micros: 6\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 4\n",
      "          allocator_name: \"cpu\"\n",
      "          ptr: 4427035168\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_1/min = Const()\"\n",
      "    scheduled_micros: 1521353938531670\n",
      "    memory_stats {\n",
      "      host_persistent_memory_size: 4\n",
      "      host_persistent_tensor_alloc_ids: -1\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_1/RandomUniform\"\n",
      "    all_start_micros: 1521353938531657\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 14\n",
      "    all_end_rel_micros: 20\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1521353938531665\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "      allocation_records {\n",
      "        alloc_micros: 1521353938531741\n",
      "        alloc_bytes: -16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 4399683744\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_1/RandomUniform = RandomUniform(random_uniform_1/shape)\"\n",
      "    scheduled_micros: 1521353938531640\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_1/mul\"\n",
      "    all_start_micros: 1521353938531707\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 6\n",
      "    all_end_rel_micros: 10\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 4399683744\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_1/mul = Mul(random_uniform_1/RandomUniform, random_uniform_1/sub)\"\n",
      "    scheduled_micros: 1521353938531677\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"random_uniform_1\"\n",
      "    all_start_micros: 1521353938531721\n",
      "    op_end_rel_micros: 3\n",
      "    all_end_rel_micros: 6\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          ptr: 4399683744\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"random_uniform_1 = Add(random_uniform_1/mul, random_uniform_1/min)\"\n",
      "    scheduled_micros: 1521353938531717\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"MatMul_1\"\n",
      "    all_start_micros: 1521353938531729\n",
      "    op_start_rel_micros: 1\n",
      "    op_end_rel_micros: 8\n",
      "    all_end_rel_micros: 13\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "      total_bytes: 16\n",
      "      peak_bytes: 16\n",
      "      live_bytes: 16\n",
      "      allocation_records {\n",
      "        alloc_micros: 1521353938531732\n",
      "        alloc_bytes: 16\n",
      "      }\n",
      "    }\n",
      "    output {\n",
      "      tensor_description {\n",
      "        dtype: DT_FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "        }\n",
      "        allocation_description {\n",
      "          requested_bytes: 16\n",
      "          allocated_bytes: 16\n",
      "          allocator_name: \"cpu\"\n",
      "          allocation_id: 1\n",
      "          has_single_reference: true\n",
      "          ptr: 4399695168\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    timeline_label: \"MatMul_1 = MatMul(MatMul_1/a, random_uniform_1)\"\n",
      "    scheduled_micros: 1521353938531727\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "  node_stats {\n",
      "    node_name: \"_retval_MatMul_1_0_0\"\n",
      "    all_start_micros: 1521353938531745\n",
      "    op_end_rel_micros: 2\n",
      "    all_end_rel_micros: 5\n",
      "    memory {\n",
      "      allocator_name: \"cpu\"\n",
      "    }\n",
      "    timeline_label: \"_retval_MatMul_1_0_0 = _Retval(MatMul_1)\"\n",
      "    scheduled_micros: 1521353938531742\n",
      "    memory_stats {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = tf.matmul([[37.0, -23.0], [1.0, 4.0]], tf.random_uniform([2, 2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Define options for the `sess.run()` call.\n",
    "    options = tf.RunOptions()\n",
    "    options.output_partition_graphs = True\n",
    "    options.trace_level = tf.RunOptions.FULL_TRACE\n",
    "\n",
    "  # Define a container for the returned metadata.\n",
    "    metadata = tf.RunMetadata()\n",
    "\n",
    "    sess.run(y, options=options, run_metadata=metadata)\n",
    "\n",
    "  # Print the subgraphs that executed on each device.\n",
    "    print(metadata.partition_graphs)\n",
    "\n",
    "  # Print the timings of each operation that executed.\n",
    "    print(metadata.step_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 可视化图\n",
    "这部分放在另一个<a href = \"\">visualization tutorial</a>啦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
