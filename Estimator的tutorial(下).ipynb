{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ›å»ºè‡ªå®šä¹‰Estimators\n",
    "è¿™ç¯‡tutorialä»‹ç»äº†å¦‚ä½•è‡ªå®šä¹‰Estimatorï¼Œç‰¹åˆ«æ˜¯ï¼Œå¦‚ä½•ä¿è¯å’Œæˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„pre-made Estimatorså…·æœ‰ç±»ä¼¼çš„åŠŸèƒ½ä¸æ¥å£\n",
    "<br>ï¼ˆæˆ‘ä»¬ç»§ç»­ç”¨é¸¢å°¾èŠ±å½“ä¾‹å­\n",
    "<img src = \"https://gss2.bdstatic.com/9fo3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike80%2C5%2C5%2C80%2C26/sign=6e3294171bd8bc3ed2050e98e3e2cd7b/86d6277f9e2f07082a8b0b2deb24b899a901f214.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.è‡ªå®šä¹‰Estimatorä¸Pre-made Estimatorçš„ä¸åŒ\n",
    "å¦‚ğŸ‘‡å›¾æ‰€ç¤ºï¼Œpre-made estimatoræ˜¯tf.estimator.Estimatorçš„å­ç±»ï¼Œä½†æ˜¯è‡ªå®šä¹‰çš„Estimatoråˆ™æ˜¯ç¤ºä¾‹\n",
    "<img src = \"https://www.tensorflow.org/images/custom_estimators/estimator_types.png?hl=zh-cn\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»æ“ä½œä¸Šæ¥çœ‹ï¼Œå”¯ä¸€åŒºåˆ«æ˜¯ï¼Œè‡ªå®šä¹‰Estimatoréœ€è¦è‡ªå·±å†™å®ç°ç®—æ³•ï¼ˆæ˜¯ä¸æ˜¯å’Œæ²¡è¯´ä¸€æ ·\n",
    "<br>è¿˜æ˜¯çœ‹å…·ä½“ä¾‹å­å¥½å•¦, ä¾‹å¦‚æˆ‘ä»¬æƒ³å®ç°é¸¢å°¾èŠ±çš„åˆ†ç±»é—®é¢˜ï¼Œé‚£ä¹ˆå¤§æ¦‚éœ€è¦å»ºç«‹ä»¥ä¸‹ğŸ‘‡è¿™æ ·çš„æ¨¡å‹\n",
    "<img src = \"https://www.tensorflow.org/images/custom_estimators/full_network.png?hl=zh-cn\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.ğŸŒ°\n",
    "#### 2.1 Input Function\n",
    "æˆ‘ä»¬è‡ªå®šä¹‰çš„Estimatorçš„è¾“å…¥å‡½æ•°é‡‡ç”¨å’Œä¹‹å‰pre-made Estimatorç›¸åŒçš„å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import iris_data\n",
    "(train_x, train_y), (test_x, test_y) = iris_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 è‡ªå®šä¹‰ç‰¹å¾åˆ—\n",
    "ç‰¹å¾åˆ—éƒ¨åˆ†ä¹Ÿåœ¨<a href = \"\">ä¹‹å‰çš„tutorial</a>ä¸­è®²è¿‡å•¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 å†™æ¨¡å‹å‡½æ•°\n",
    "å½“å®šä¹‰ä¸€ä¸ªæ¨¡å‹å‡½æ•°ï¼Œæˆ‘ä»¬éœ€è¦ä¼ å…¥ä»Input functionä¸­è¿”å›çš„featuresä»¥åŠlabelsï¼Œè¿™äº›æ˜¯æˆ‘ä»¬å®šä¹‰çš„æ¨¡å‹ç›´æ¥è¦ç”¨åˆ°çš„æ•°æ®ï¼Œmodeå‚æ•°æ˜¯ç”¨æ¥åªæ˜¯æˆ‘ä»¬è°ƒç”¨çš„æ˜¯ä½•ç§æ–¹æ³•ï¼Œæ˜¯trainï¼Œpredictè¿˜æ˜¯evaluateï¼Œæ‰€ä»¥åŒæ ·çš„ï¼Œä½ éœ€è¦å‡ºè¿™ä¸‰ç§æ¨¡å¼ä¸‹æ‰€éœ€çš„è®¡ç®—ã€‚\n",
    "#### æ€»ç»“æ¥è¯´ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ¨¡å‹å‡½æ•°ï¼Œéœ€è¦åšä»¥ä¸‹å·¥ä½œï¼š\n",
    "* å®šä¹‰æ¨¡å‹\n",
    "* æŒ‡å®šä¸åŒæ¨¡å¼ä¸‹çš„è®¡ç®—\n",
    " * Train\n",
    " * Evaluate\n",
    " * Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 æˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹å®šä¹‰æ¨¡å‹\n",
    "ä¸€ä¸ªåŸºæœ¬çš„æ·±åº¦ç¥ç»ç½‘ç»œåŒ…æ‹¬ä»¥ä¸‹ä¸‰éƒ¨åˆ†ï¼š\n",
    "* ä¸€ä¸ªè¾“å…¥å±‚\n",
    "* è‡³å°‘ä¸€å±‚éšè—å±‚\n",
    "* ä¸€ä¸ªè¾“å‡ºå±‚\n",
    "\n",
    "<BR>\n",
    "* å®šä¹‰ä¸€ä¸ªè¾“å…¥å±‚,æˆ‘ä»¬å¯ä»¥ç›´æ¥è°ƒç”¨tf.feature_column.input_layeræ–¹æ³•æ¥å°†ç‰¹å¾å­—å…¸å’Œç‰¹å¾åˆ—è½¬åŒ–ä¸ºæ¨¡å‹è¾“å…¥\n",
    "    * net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    <img src = \"https://www.tensorflow.org/images/custom_estimators/input_layer.png?hl=zh-cn\">\n",
    "    \n",
    "<BR>\n",
    "* å…³äºå®šä¹‰éšè—å±‚ï¼Œtensorflowæä¾›çš„layersæ¥å£æä¾›äº†å„ç§æ–¹æ³•ï¼Œå¯ä»¥è‡ªè¡Œè®¾ç½®å·ç§¯ï¼Œæ± åŒ–ç­‰ã€‚ä½†å¯¹äºé¸¢å°¾èŠ±æ•°æ®é›†ï¼Œç”±äºè¯¥æ•°æ®é›†æ¯”è¾ƒç®€å•ï¼Œæˆ‘ä»¬åªéœ€è¦è°ƒç”¨ç®€å•çš„å…¨è¿æ¥å±‚æ¥å®šä¹‰éšè—å±‚(tf.layers.dense),å…¶ä¸­æ¯ä¸€å±‚çš„å•å…ƒæ•°åœ¨params['hidden_layers']ä¸­å®šä¹‰\n",
    "    * for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "\n",
    " å…³äºä»¥ä¸Šä»£ç ä¸€ç‚¹é¢å¤–è¯´æ˜ï¼šåœ¨æ¯æ¬¡è¿­ä»£å»ºç«‹éšè—å±‚è¿‡ç¨‹ä¸­ï¼Œå½“å‰å±‚ä»¥ä¸Šä¸€å±‚ä½œä¸ºè¾“å…¥\n",
    "     <img src = \"https://www.tensorflow.org/images/custom_estimators/add_hidden_layer.png?hl=zh-cn\">\n",
    " \n",
    "<BR>\n",
    "* å…³äºè¾“å‡ºå±‚ï¼Œè¿™é‡Œæˆ‘ä»¬ç»§ç»­è°ƒç”¨tf.layers.denseæ¥å»ºç«‹è¾“å‡ºå±‚ï¼Œä½†æ³¨æ„è¾“å‡ºå±‚æ²¡æœ‰æ¿€æ´»å‡½æ•°\n",
    "   * logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
    "   <img src = \"https://www.tensorflow.org/images/custom_estimators/add_logits.png?hl=zh-cn\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 å®ç°è®­ç»ƒï¼Œè¯„ä¼°å’Œé¢„æµ‹æ¨¡å¼\n",
    "æˆ‘ä»¬åœ¨å®šä¹‰è‡ªå·±çš„æ¨¡å‹å‡½æ•°æ—¶ï¼Œéœ€è¦æŒ‡å®šè¿™æ¬¡è®¡ç®—æ˜¯è®­ç»ƒæ¨¡å¼ï¼Œè¯„ä¼°æ¨¡å¼è¿˜æ˜¯é¢„æµ‹æ¨¡å¼ï¼Œé‚£è¿™æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å®šä¹‰è‡ªå·±çš„æ¨¡å‹å‡½æ•°æ—¶ï¼Œå‡ºå…¥ä¸€ä¸ªmodeå‚æ•°ï¼Œæ¥æŒ‡å®šæœ¬æ¬¡è®¡ç®—çš„æ¨¡å¼ï¼š\n",
    "<br >def my_model_fn( features, labels, mode, params): \n",
    "* å…³äºmodeå‚æ•°ï¼š\n",
    "  å½“æˆ‘ä»¬æƒ³è°ƒç”¨trainï¼Œevaluateæˆ–è€…predictæ–¹æ³•æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡ç‰¹å®šçš„modeå‚æ•°æ¥å”¤é†’è¿™äº›æ–¹æ³•ï¼š\n",
    "  * ModeKeys.TRAIN ---> train()\n",
    "  * ModeKeys.EVAL ---> evaluate()\n",
    "  * ModeKeys.PREDICT ---> predict()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the loss\n",
    "åœ¨æ¥ä¸‹æ¥çš„è®­ç»ƒå’Œè¯„ä¼°æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬éƒ½éœ€è¦è®¡ç®—æ¨¡å‹çš„æŸå¤±ï¼Œä¹Ÿå°±æ˜¯éœ€è¦è¢«ä¼˜åŒ–çš„å¯¹è±¡ï¼›æˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨tf.losses.sparse_softmax_cross_entropyæ¥è®¡ç®—æ¨¡å‹æŸå¤±ï¼š\n",
    "* loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "å…³äºè®­ç»ƒæ¨¡å¼ï¼Œå½“Estimatorçš„trainæ–¹æ³•è¢«è°ƒç”¨æ—¶ï¼Œç›¸åº”çš„ï¼Œæ¨¡å‹å‡½æ•°è¢« mode = ModeKeys.TRAIN å”¤é†’ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹å‡½æ•°å¿…é¡»è¿”å›ä¸€ä¸ª<a href = \"\">EstimatorSpec</a>ï¼ŒåŒ…å«è®¡ç®—å¾—åˆ°çš„æŸå¤±ä»¥åŠè®­ç»ƒæ–¹æ³•ï¼š\n",
    "  å»ºç«‹è®­ç»ƒæ“ä½œéœ€è¦æˆ‘ä»¬å®šä¹‰ä¼˜åŒ–å™¨ï¼Œæˆ‘ä»¬é€šå¸¸ç”¨tf.train.AdagradOptimizerä½œä¸ºé»˜è®¤ä¼˜åŒ–å™¨ï¼ˆtf.trainä¸­ä¹Ÿæä¾›äº†è®¸å¤šå…¶ä»–ä¼˜åŒ–å™¨ï¼‰\n",
    "  * optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "  \n",
    "<br>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç”¨åˆšåˆšå®šä¹‰çš„ä¼˜åŒ–å™¨æ¥æœ€å°åŒ–æ¨¡å‹æŸå¤±ï¼Œä¼˜åŒ–å™¨çš„æœ€å°åŒ–æ–¹æ³•ï¼Œå¸¦æœ‰ä¸€ä¸ªglobal_stepå‚æ•°ï¼ŒTensorFlowç”¨è¯¥å‚æ•°æ¥è®¡ç®—å·²ç»è®­ç»ƒçš„æ¬¡æ•°ï¼ˆæ¥ç¡®å®šè®­ç»ƒä½•æ—¶ç»“æŸï¼‰,é™¤æ­¤ä»¥å¤–ï¼Œglobal_stepå‚æ•°å¯¹äºTensorBoardå›¾å½¢åŒ–æ¨¡å‹éå¸¸å¿…è¦ï¼Œç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š\n",
    "  * train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "  \n",
    "<br>è¿”å›çš„EstimatorSpecå¿…é¡»åŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼š\n",
    "      * loss: åŒ…å«æŸå¤±å‡½æ•°å€¼\n",
    "      * train_op: å¯æ‰§è¡Œçš„è®­ç»ƒæ–¹æ³•\n",
    "      <br>ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š\n",
    "      * return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "ç±»ä¼¼çš„ï¼Œå½“Estimatorçš„è¯„ä¼°æ–¹æ³•è¢«è°ƒç”¨æ—¶ï¼Œmodel_fnæ¥æ”¶åˆ°äº†mode = ModeKeys.EVAL, åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹å‡½æ•°éœ€è¦è¿”å›ä¸€ä¸ªåŒ…å«æ¨¡å‹æŸå¤±ä»¥åŠå¯é€‰æ‹©çš„çŸ©é˜µã€‚\n",
    "<br>(ä½ å¯èƒ½éœ€è¦æŸ¥çœ‹<a href = \"\">å…³äºMetricçš„tutorial</a>)\n",
    "<br>å°½ç®¡è¿”å›çŸ©é˜µæ˜¯å¯é€‰æ‹©çš„ï¼Œå¤§å¤šæ•°è‡ªå®šä¹‰Estimatoréƒ½è‡³å°‘ä¼šè¿”å›ä¸€ä¸ªçŸ©é˜µï¼ŒTensorFlowæä¾›äº†çŸ©é˜µæ¨¡å—ï¼Œæ¥è®¡ç®—ä¸€äº›å¸¸ç”¨çŸ©é˜µï¼Œåœ¨å½“å‰è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é»˜è®¤è¿”å›AccuracyçŸ©é˜µï¼š\n",
    "* accuracy = tf.metrics.accuracy(labels=labels,predictions=predicted_classes, name='acc_op')\n",
    "\n",
    "<BR>\n",
    "åœ¨å®é™…ç¼–ç¨‹ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½ä¸ä»…åˆ›å»ºä¸€ä¸ªçŸ©é˜µï¼Œæ‰€ä»¥ï¼Œåœ¨è¿”å›ç»“æœä¹‹å‰ï¼Œåˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå°†æˆ‘ä»¬åˆ›å»ºçš„æ¯ä¸ªçŸ©é˜µé™„åˆ°å­—å…¸ä¸­ä¸€å¹¶è¿”å›ï¼Œç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š\n",
    "* metrics = {'accuracy': accuracy}\n",
    "\n",
    "æœ€ç»ˆè¿”å›ï¼š\n",
    "* return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
    "æ­¤å¤–ï¼Œä¸ºäº†åœ¨TensorBoardä¸­ï¼Œaccuracyåœ¨TrainåŠEvalæ¨¡å¼ä¸‹éƒ½å¯ä»¥å¯è§†åŒ–ï¼Œéœ€è¦åŠ ä¸Šï¼š\n",
    "* tf.summary.scalar('accuracy', accuracy[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict\n",
    "å—¯ï¼Œè¿˜æ˜¯ç±»ä¼¼çš„ï¼Œå½“Estimatorçš„é¢„æµ‹æ–¹æ³•è¢«è°ƒç”¨ï¼ŒModel_fnå°†ä¼šæ”¶åˆ°mode = ModeKeys.PREDICT; \n",
    "<br>åœ¨è°ƒç”¨é¢„æµ‹æ¨¡å¼ä¹‹å‰ï¼Œè¯¥æ¨¡å‹å¿…é¡»å·²ç»è®­ç»ƒã€‚è®­ç»ƒåçš„æ¨¡å‹å­˜å‚¨åœ¨model_dirç›®å½•ä¸‹ï¼Œåœ¨åˆå§‹åŒ–Estimatoræ—¶è¢«é‡å»ºã€‚\n",
    "<br>é¢„æµ‹æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹èŒƒæ•°å¿…é¡»è¿”å›ç›¸åº”çš„é¢„æµ‹å€¼, ç”Ÿæˆé¢„æµ‹å€¼å¾—ä»£ç å¦‚ä¸‹ï¼š\n",
    "* predicted_classes = tf.argmax(logits, 1)\n",
    "* predictions = {\n",
    "        'class_ids': predicted_classes[:, tf.newaxis],\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "        'logits': logits,}\n",
    "<br>predictionså­—å…¸ä¸­åŒ…å«äº†æˆ‘ä»¬éœ€è¦çš„æ‰€æœ‰ä¿¡æ¯ï¼š\n",
    "<img src = \"https://www.tensorflow.org/images/custom_estimators/add_predictions.png?hl=zh-cn\">\n",
    "* æˆ‘ä»¬åªéœ€è¦è¿”å›predictionså­—å…¸å³å¯ï¼š\n",
    "    * return tf.estimator.EstimatorSpec(mode, predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ä»¥ä¸‹æ˜¯åˆšåˆšå…¨éƒ¨å†…å®¹çš„æ•´åˆä½“\n",
    "def my_model(features, labels, mode, params):\n",
    "    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n",
    "    # Create three fully connected layers each layer having a dropout\n",
    "    # probability of 0.1.\n",
    "    net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "    for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "\n",
    "    # Compute logits (1 per class).\n",
    "    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n",
    "\n",
    "    # Compute predictions.\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': predicted_classes[:, tf.newaxis],\n",
    "            'probabilities': tf.nn.softmax(logits),\n",
    "            'logits': logits,\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Compute evaluation metrics.\n",
    "    accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                   predictions=predicted_classes,\n",
    "                                   name='acc_op')\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 åˆå§‹åŒ–æ¨¡å‹\n",
    "ä¸€äº›å…¶ä»–çš„å‚æ•°ï¼Œå¯èƒ½éœ€è¦åœ¨å»ºç«‹Estimatorä¸­éœ€è¦ç”¨åˆ°ï¼Œè¿™äº›å‚æ•°ç”¨äºè®¾ç½®æ¨¡å‹ï¼Œä¾‹å¦‚éšè—å±‚çš„æ•°é‡ï¼Œæ¯ä¸€å±‚å•å…ƒçš„ä¸ªæ•°ï¼Œè¾“å‡ºå±‚çš„ç»´åº¦ï¼Œç­‰ç­‰ï¼Œè®¾ç½®æ–¹æ³•ä¸æˆ‘ä»¬ä¹‹å‰è°ƒç”¨pre-made Estimatoræ—¶çš„è®¾ç½®æ–¹æ³•ç±»ä¼¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model/iris', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11ea03160>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns': my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        'hidden_units': [10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        'n_classes': 3,\n",
    "    },\n",
    "    model_dir = 'model/iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 è®­ç»ƒç¤ºä¾‹\n",
    "è®­ç»ƒï¼Œè¯„ä¼°ï¼Œé¢„æµ‹ç­‰æ–¹æ³•ï¼Œä¸æˆ‘ä»¬åœ¨pre-made Estimatorä¸­è§åˆ°çš„ä¸€æ ·ï¼Œè¿™é‡Œç»™å‡ºç®€å•æ ·ä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into model/iris/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.5508926, step = 1\n",
      "INFO:tensorflow:global_step/sec: 543.564\n",
      "INFO:tensorflow:loss = 0.32071263, step = 101 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.435\n",
      "INFO:tensorflow:loss = 0.06946964, step = 201 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.824\n",
      "INFO:tensorflow:loss = 0.06918395, step = 301 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.35\n",
      "INFO:tensorflow:loss = 0.05326658, step = 401 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.684\n",
      "INFO:tensorflow:loss = 0.09533507, step = 501 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.89\n",
      "INFO:tensorflow:loss = 0.06499552, step = 601 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.439\n",
      "INFO:tensorflow:loss = 0.086014576, step = 701 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.628\n",
      "INFO:tensorflow:loss = 0.11016789, step = 801 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 682.361\n",
      "INFO:tensorflow:loss = 0.0517772, step = 901 (0.147 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model/iris/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.052121107.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x11ea032e8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_x, train_y, 100),\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ä»¥ä¸Šå°±æ˜¯å…³äºEstimatoréƒ¨åˆ†çš„å…¨éƒ¨å†…å®¹å•¦~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
